//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-33961263
// Cuda compilation tools, release 12.4, V12.4.99
// Based on NVVM 7.0.1
//

.version 8.4
.target sm_52
.address_size 64

	// .globl	osgm_band_kernel
.extern .shared .align 16 .b8 shared[];

.visible .entry osgm_band_kernel(
	.param .u64 osgm_band_kernel_param_0,
	.param .u64 osgm_band_kernel_param_1,
	.param .u64 osgm_band_kernel_param_2,
	.param .u64 osgm_band_kernel_param_3,
	.param .u64 osgm_band_kernel_param_4,
	.param .u32 osgm_band_kernel_param_5,
	.param .f64 osgm_band_kernel_param_6,
	.param .f64 osgm_band_kernel_param_7,
	.param .f64 osgm_band_kernel_param_8,
	.param .u32 osgm_band_kernel_param_9
)
{
	.reg .pred 	%p<29>;
	.reg .f32 	%f<52>;
	.reg .b32 	%r<103>;
	.reg .f64 	%fd<86>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd4, [osgm_band_kernel_param_0];
	ld.param.u64 	%rd6, [osgm_band_kernel_param_1];
	ld.param.u64 	%rd7, [osgm_band_kernel_param_2];
	ld.param.u64 	%rd8, [osgm_band_kernel_param_3];
	ld.param.u64 	%rd5, [osgm_band_kernel_param_4];
	ld.param.u32 	%r48, [osgm_band_kernel_param_5];
	ld.param.f64 	%fd17, [osgm_band_kernel_param_6];
	ld.param.f64 	%fd18, [osgm_band_kernel_param_7];
	ld.param.f64 	%fd19, [osgm_band_kernel_param_8];
	ld.param.u32 	%r49, [osgm_band_kernel_param_9];
	cvta.to.global.u64 	%rd1, %rd8;
	cvta.to.global.u64 	%rd2, %rd7;
	cvta.to.global.u64 	%rd3, %rd6;
	mov.u32 	%r50, %ctaid.x;
	mov.u32 	%r1, %ntid.x;
	mul.lo.s32 	%r2, %r50, %r1;
	mov.u32 	%r3, %tid.x;
	add.s32 	%r4, %r2, %r3;
	setp.ge.s32 	%p1, %r4, %r48;
	shl.b32 	%r51, %r3, 3;
	mov.u32 	%r52, shared;
	add.s32 	%r5, %r52, %r51;
	@%p1 bra 	$L__BB0_2;

	cvta.to.global.u64 	%rd9, %rd4;
	mul.wide.s32 	%rd10, %r4, 8;
	add.s64 	%rd11, %rd9, %rd10;
	ld.global.nc.f64 	%fd20, [%rd11];
	st.shared.f64 	[%r5], %fd20;
	add.s64 	%rd12, %rd3, %rd10;
	ld.global.nc.f64 	%fd21, [%rd12];
	add.s32 	%r53, %r1, %r3;
	add.s32 	%r54, %r53, %r49;
	shl.b32 	%r55, %r54, 3;
	add.s32 	%r57, %r52, %r55;
	st.shared.f64 	[%r57], %fd21;

$L__BB0_2:
	setp.ge.s32 	%p2, %r3, %r49;
	@%p2 bra 	$L__BB0_6;

	sub.s32 	%r58, %r2, %r49;
	add.s32 	%r6, %r58, %r3;
	setp.gt.s32 	%p3, %r6, -1;
	add.s32 	%r59, %r1, %r3;
	shl.b32 	%r60, %r59, 3;
	add.s32 	%r7, %r52, %r60;
	@%p3 bra 	$L__BB0_5;
	bra.uni 	$L__BB0_4;

$L__BB0_5:
	mul.wide.s32 	%rd14, %r6, 8;
	add.s64 	%rd15, %rd3, %rd14;
	ld.global.nc.f64 	%fd22, [%rd15];
	st.shared.f64 	[%r7], %fd22;
	bra.uni 	$L__BB0_6;

$L__BB0_4:
	mov.u64 	%rd13, 0;
	st.shared.u64 	[%r7], %rd13;

$L__BB0_6:
	sub.s32 	%r62, %r1, %r49;
	setp.lt.u32 	%p4, %r3, %r62;
	setp.ge.u32 	%p5, %r3, %r1;
	or.pred  	%p6, %p5, %p4;
	@%p6 bra 	$L__BB0_10;

	add.s32 	%r63, %r2, %r1;
	sub.s32 	%r64, %r49, %r1;
	add.s32 	%r65, %r64, %r3;
	add.s32 	%r8, %r63, %r65;
	setp.lt.s32 	%p7, %r8, %r48;
	shl.b32 	%r66, %r1, 1;
	add.s32 	%r67, %r66, %r49;
	add.s32 	%r68, %r67, %r65;
	shl.b32 	%r69, %r68, 3;
	add.s32 	%r9, %r52, %r69;
	@%p7 bra 	$L__BB0_9;
	bra.uni 	$L__BB0_8;

$L__BB0_9:
	mul.wide.s32 	%rd17, %r8, 8;
	add.s64 	%rd18, %rd3, %rd17;
	ld.global.nc.f64 	%fd23, [%rd18];
	st.shared.f64 	[%r9], %fd23;
	bra.uni 	$L__BB0_10;

$L__BB0_8:
	mov.u64 	%rd16, 0;
	st.shared.u64 	[%r9], %rd16;

$L__BB0_10:
	bar.sync 	0;
	@%p1 bra 	$L__BB0_29;

	ld.shared.f64 	%fd1, [%r5];
	neg.s32 	%r95, %r49;
	setp.gt.s32 	%p9, %r95, %r49;
	mov.f64 	%fd81, 0d0000000000000000;
	@%p9 bra 	$L__BB0_28;

	add.f64 	%fd27, %fd17, 0d3BC79CA100000000;
	cvt.rn.f32.f64 	%f1, %fd27;
	max.s32 	%r71, %r95, %r49;
	add.s32 	%r11, %r71, %r49;
	add.s32 	%r72, %r11, 1;
	and.b32  	%r94, %r72, 3;
	setp.eq.s32 	%p10, %r94, 0;
	mov.f64 	%fd81, 0d0000000000000000;
	@%p10 bra 	$L__BB0_17;

	add.s32 	%r73, %r3, %r1;
	shl.b32 	%r74, %r73, 3;
	add.s32 	%r91, %r52, %r74;
	sub.s32 	%r90, %r4, %r49;
	mov.f64 	%fd81, 0d0000000000000000;
	mov.u32 	%r92, %r4;

$L__BB0_14:
	.pragma "nounroll";
	setp.ge.s32 	%p11, %r90, %r48;
	setp.lt.s32 	%p12, %r90, 0;
	or.pred  	%p13, %p12, %p11;
	@%p13 bra 	$L__BB0_16;

	ld.shared.f64 	%fd29, [%r91];
	mul.f64 	%fd30, %fd1, %fd29;
	cvt.rn.f32.f64 	%f2, %fd30;
	div.approx.f32 	%f3, %f2, %f1;
	neg.f32 	%f4, %f3;
	cvt.f64.f32 	%fd31, %f3;
	mul.wide.s32 	%rd19, %r92, 8;
	add.s64 	%rd20, %rd2, %rd19;
	add.s64 	%rd21, %rd1, %rd19;
	ld.global.f64 	%fd32, [%rd20];
	cvt.rn.f32.f64 	%f5, %fd32;
	fma.rn.f32 	%f6, %f4, %f4, %f5;
	cvt.f64.f32 	%fd33, %f6;
	add.f64 	%fd34, %fd33, %fd18;
	cvt.rn.f32.f64 	%f7, %fd34;
	rsqrt.approx.f32 	%f8, %f7;
	mul.f64 	%fd35, %fd31, %fd19;
	cvt.rn.f32.f64 	%f9, %fd35;
	ld.global.f64 	%fd36, [%rd21];
	cvt.rn.f32.f64 	%f10, %fd36;
	fma.rn.f32 	%f11, %f9, %f8, %f10;
	cvt.f64.f32 	%fd37, %f11;
	fma.rn.f64 	%fd81, %fd29, %fd37, %fd81;
	st.global.f64 	[%rd20], %fd33;
	st.global.f64 	[%rd21], %fd37;

$L__BB0_16:
	add.s32 	%r95, %r95, 1;
	add.s32 	%r92, %r92, %r48;
	add.s32 	%r91, %r91, 8;
	add.s32 	%r90, %r90, 1;
	add.s32 	%r94, %r94, -1;
	setp.ne.s32 	%p14, %r94, 0;
	@%p14 bra 	$L__BB0_14;

$L__BB0_17:
	setp.lt.u32 	%p15, %r11, 3;
	@%p15 bra 	$L__BB0_28;

	add.s32 	%r101, %r95, -1;
	add.s32 	%r76, %r95, %r49;
	add.s32 	%r77, %r76, 3;
	mad.lo.s32 	%r100, %r48, %r77, %r4;
	shl.b32 	%r28, %r48, 2;
	mad.lo.s32 	%r99, %r48, %r76, %r4;
	add.s32 	%r78, %r3, %r95;
	add.s32 	%r79, %r78, %r2;
	add.s32 	%r80, %r76, 2;
	mad.lo.s32 	%r98, %r48, %r80, %r4;
	add.s32 	%r81, %r76, 1;
	mad.lo.s32 	%r97, %r48, %r81, %r4;
	add.s32 	%r96, %r79, 1;
	add.s32 	%r82, %r3, %r1;
	add.s32 	%r83, %r82, %r95;
	add.s32 	%r84, %r83, %r49;
	shl.b32 	%r85, %r84, 3;
	add.s32 	%r102, %r52, %r85;

$L__BB0_19:
	.pragma "nounroll";
	add.s32 	%r87, %r96, -1;
	setp.lt.s32 	%p16, %r87, 0;
	setp.ge.s32 	%p17, %r87, %r48;
	or.pred  	%p18, %p16, %p17;
	@%p18 bra 	$L__BB0_21;

	ld.shared.f64 	%fd38, [%r102];
	mul.f64 	%fd39, %fd1, %fd38;
	cvt.rn.f32.f64 	%f12, %fd39;
	div.approx.f32 	%f13, %f12, %f1;
	neg.f32 	%f14, %f13;
	cvt.f64.f32 	%fd40, %f13;
	mul.wide.s32 	%rd22, %r99, 8;
	add.s64 	%rd23, %rd2, %rd22;
	add.s64 	%rd24, %rd1, %rd22;
	ld.global.f64 	%fd41, [%rd23];
	cvt.rn.f32.f64 	%f15, %fd41;
	fma.rn.f32 	%f16, %f14, %f14, %f15;
	cvt.f64.f32 	%fd42, %f16;
	add.f64 	%fd43, %fd42, %fd18;
	cvt.rn.f32.f64 	%f17, %fd43;
	rsqrt.approx.f32 	%f18, %f17;
	mul.f64 	%fd44, %fd40, %fd19;
	cvt.rn.f32.f64 	%f19, %fd44;
	ld.global.f64 	%fd45, [%rd24];
	cvt.rn.f32.f64 	%f20, %fd45;
	fma.rn.f32 	%f21, %f19, %f18, %f20;
	cvt.f64.f32 	%fd46, %f21;
	fma.rn.f64 	%fd81, %fd38, %fd46, %fd81;
	st.global.f64 	[%rd23], %fd42;
	st.global.f64 	[%rd24], %fd46;

$L__BB0_21:
	setp.ge.s32 	%p19, %r96, %r48;
	setp.lt.s32 	%p20, %r96, 0;
	or.pred  	%p21, %p20, %p19;
	@%p21 bra 	$L__BB0_23;

	ld.shared.f64 	%fd47, [%r102+8];
	mul.f64 	%fd48, %fd1, %fd47;
	cvt.rn.f32.f64 	%f22, %fd48;
	div.approx.f32 	%f23, %f22, %f1;
	neg.f32 	%f24, %f23;
	cvt.f64.f32 	%fd49, %f23;
	mul.wide.s32 	%rd25, %r97, 8;
	add.s64 	%rd26, %rd2, %rd25;
	add.s64 	%rd27, %rd1, %rd25;
	ld.global.f64 	%fd50, [%rd26];
	cvt.rn.f32.f64 	%f25, %fd50;
	fma.rn.f32 	%f26, %f24, %f24, %f25;
	cvt.f64.f32 	%fd51, %f26;
	add.f64 	%fd52, %fd51, %fd18;
	cvt.rn.f32.f64 	%f27, %fd52;
	rsqrt.approx.f32 	%f28, %f27;
	mul.f64 	%fd53, %fd49, %fd19;
	cvt.rn.f32.f64 	%f29, %fd53;
	ld.global.f64 	%fd54, [%rd27];
	cvt.rn.f32.f64 	%f30, %fd54;
	fma.rn.f32 	%f31, %f29, %f28, %f30;
	cvt.f64.f32 	%fd55, %f31;
	fma.rn.f64 	%fd81, %fd47, %fd55, %fd81;
	st.global.f64 	[%rd26], %fd51;
	st.global.f64 	[%rd27], %fd55;

$L__BB0_23:
	add.s32 	%r88, %r96, 1;
	setp.lt.s32 	%p22, %r88, 0;
	setp.ge.s32 	%p23, %r88, %r48;
	or.pred  	%p24, %p22, %p23;
	@%p24 bra 	$L__BB0_25;

	ld.shared.f64 	%fd56, [%r102+16];
	mul.f64 	%fd57, %fd1, %fd56;
	cvt.rn.f32.f64 	%f32, %fd57;
	div.approx.f32 	%f33, %f32, %f1;
	neg.f32 	%f34, %f33;
	cvt.f64.f32 	%fd58, %f33;
	mul.wide.s32 	%rd28, %r98, 8;
	add.s64 	%rd29, %rd2, %rd28;
	add.s64 	%rd30, %rd1, %rd28;
	ld.global.f64 	%fd59, [%rd29];
	cvt.rn.f32.f64 	%f35, %fd59;
	fma.rn.f32 	%f36, %f34, %f34, %f35;
	cvt.f64.f32 	%fd60, %f36;
	add.f64 	%fd61, %fd60, %fd18;
	cvt.rn.f32.f64 	%f37, %fd61;
	rsqrt.approx.f32 	%f38, %f37;
	mul.f64 	%fd62, %fd58, %fd19;
	cvt.rn.f32.f64 	%f39, %fd62;
	ld.global.f64 	%fd63, [%rd30];
	cvt.rn.f32.f64 	%f40, %fd63;
	fma.rn.f32 	%f41, %f39, %f38, %f40;
	cvt.f64.f32 	%fd64, %f41;
	fma.rn.f64 	%fd81, %fd56, %fd64, %fd81;
	st.global.f64 	[%rd29], %fd60;
	st.global.f64 	[%rd30], %fd64;

$L__BB0_25:
	add.s32 	%r89, %r96, 2;
	setp.lt.s32 	%p25, %r89, 0;
	setp.ge.s32 	%p26, %r89, %r48;
	or.pred  	%p27, %p25, %p26;
	@%p27 bra 	$L__BB0_27;

	ld.shared.f64 	%fd65, [%r102+24];
	mul.f64 	%fd66, %fd1, %fd65;
	cvt.rn.f32.f64 	%f42, %fd66;
	div.approx.f32 	%f43, %f42, %f1;
	neg.f32 	%f44, %f43;
	cvt.f64.f32 	%fd67, %f43;
	mul.wide.s32 	%rd31, %r100, 8;
	add.s64 	%rd32, %rd2, %rd31;
	add.s64 	%rd33, %rd1, %rd31;
	ld.global.f64 	%fd68, [%rd32];
	cvt.rn.f32.f64 	%f45, %fd68;
	fma.rn.f32 	%f46, %f44, %f44, %f45;
	cvt.f64.f32 	%fd69, %f46;
	add.f64 	%fd70, %fd69, %fd18;
	cvt.rn.f32.f64 	%f47, %fd70;
	rsqrt.approx.f32 	%f48, %f47;
	mul.f64 	%fd71, %fd67, %fd19;
	cvt.rn.f32.f64 	%f49, %fd71;
	ld.global.f64 	%fd72, [%rd33];
	cvt.rn.f32.f64 	%f50, %fd72;
	fma.rn.f32 	%f51, %f49, %f48, %f50;
	cvt.f64.f32 	%fd73, %f51;
	fma.rn.f64 	%fd81, %fd65, %fd73, %fd81;
	st.global.f64 	[%rd32], %fd69;
	st.global.f64 	[%rd33], %fd73;

$L__BB0_27:
	add.s32 	%r102, %r102, 32;
	add.s32 	%r100, %r100, %r28;
	add.s32 	%r99, %r99, %r28;
	add.s32 	%r98, %r98, %r28;
	add.s32 	%r97, %r97, %r28;
	add.s32 	%r96, %r96, 4;
	add.s32 	%r101, %r101, 4;
	setp.lt.s32 	%p28, %r101, %r49;
	@%p28 bra 	$L__BB0_19;

$L__BB0_28:
	cvta.to.global.u64 	%rd34, %rd5;
	mul.wide.s32 	%rd35, %r4, 8;
	add.s64 	%rd36, %rd34, %rd35;
	ld.global.f64 	%fd74, [%rd36];
	sub.f64 	%fd75, %fd74, %fd81;
	st.global.f64 	[%rd36], %fd75;

$L__BB0_29:
	ret;

}
	// .globl	fill_osgm_diagonal
.visible .entry fill_osgm_diagonal(
	.param .u64 fill_osgm_diagonal_param_0,
	.param .u64 fill_osgm_diagonal_param_1,
	.param .u32 fill_osgm_diagonal_param_2,
	.param .u32 fill_osgm_diagonal_param_3
)
{
	.reg .pred 	%p<4>;
	.reg .b32 	%r<8>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [fill_osgm_diagonal_param_0];
	ld.param.u64 	%rd2, [fill_osgm_diagonal_param_1];
	ld.param.u32 	%r2, [fill_osgm_diagonal_param_2];
	ld.param.u32 	%r3, [fill_osgm_diagonal_param_3];
	mov.u32 	%r4, %tid.x;
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mad.lo.s32 	%r1, %r6, %r5, %r4;
	setp.ge.s32 	%p1, %r1, %r2;
	setp.lt.s32 	%p2, %r1, 0;
	or.pred  	%p3, %p2, %p1;
	@%p3 bra 	$L__BB1_2;

	cvta.to.global.u64 	%rd3, %rd2;
	mad.lo.s32 	%r7, %r3, %r2, %r1;
	mul.wide.s32 	%rd4, %r1, 8;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.nc.f64 	%fd1, [%rd5];
	cvta.to.global.u64 	%rd6, %rd1;
	mul.wide.s32 	%rd7, %r7, 8;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f64 	[%rd8], %fd1;

$L__BB1_2:
	ret;

}

